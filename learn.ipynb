{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff223689",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='uer/gpt2-chinese-cluecorpussmall', vocab_size=21128, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3617, 1139, 3313, 1139, 1045, 6793, 6809, 117, 1283, 2255, 674, 2255, 1963, 4125, 1355, 119, 7557, 5640, 6624, 1403, 1921, 677, 3341, 117, 6852, 1316, 3655, 3215, 6628, 1316, 3299, 119, 102], [101, 4007, 4680, 3736, 2255, 1724, 3307, 2406, 117, 4635, 756, 7770, 1318, 2322, 4170, 3119, 119, 3189, 1726, 4896, 2512, 4959, 4541, 3312, 117, 7599, 6853, 4351, 1898, 1057, 2207, 3517, 119, 6823, 2273, 849, 2242, 3566, 4819, 5862, 117, 3171, 2359, 1963, 1383, 2779, 704, 3837, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/gpt2-chinese-cluecorpussmall')\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    '欲出未出光辣达,千山万山如火发.须臾走向天上来,逐却残星赶却月.',\n",
    "    '满目江山四望幽,白云高卷嶂烟收.日回禽影穿疏木,风递猿声入小楼.远岫似屏横碧落,断帆如叶截中流.'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc8dfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304752, '欲出未出光辣达,千山万山如火发.须臾走向天上来,逐却残星赶却月.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "#简单数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        with open('chinese_poems.txt') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [i.strip() for i in lines]\n",
    "\n",
    "        self.lines = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.lines[i]\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750a592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839587, '閒庭曲槛流霞。旧时家。记得雨中亲拾玉兰花。红羊劫。青衫客。负琼葩。一样可怜颜色在天涯。')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#更多数据数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        data = []\n",
    "        for i in os.listdir('more_datas'):\n",
    "            if i == '.ipynb_checkpoints':\n",
    "                continue\n",
    "            data.append(pd.read_csv('more_datas/%s' % i))\n",
    "\n",
    "        data = pd.concat(data).reset_index()\n",
    "\n",
    "        data = data['内容']\n",
    "\n",
    "        data = data.str.strip()\n",
    "\n",
    "        #移除一些标点符号\n",
    "        data = data.str.replace('[《》“”「」]', '', regex=True)\n",
    "\n",
    "        #正则过滤\n",
    "        select = data.str.match('^[\\w，。？、！：；]+$', na=False)\n",
    "        data = data[select]\n",
    "\n",
    "        #标点符号合并\n",
    "        data = data.str.replace('[？！；]', '。', regex=True)\n",
    "        data = data.str.replace('[、：]', '，', regex=True)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data.iloc[i]\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405095b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 338])\n",
      "token_type_ids torch.Size([8, 338])\n",
      "attention_mask torch.Size([8, 338])\n",
      "labels torch.Size([8, 338])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104948"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    data = tokenizer.batch_encode_plus(data,\n",
    "                                       padding=True,\n",
    "                                       truncation=True,\n",
    "                                       max_length=512,\n",
    "                                       return_tensors='pt')\n",
    "\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53f3c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10206.8736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(10.4425), torch.Size([8, 338, 21128]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, GPT2Model\n",
    "\n",
    "#加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'uer/gpt2-chinese-cluecorpussmall')\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd9b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS] 秋 高 气 爽 的 ， 人 均 花 一 斤 。 吃 的 菜 式 都 ， 都 没 有 什 么 。\n",
      "1 [CLS] 秋 高 气 爽 ！ ， 这 家 店 居 然 。 是 一 家 台 湾 ， 又 是 台 湾 的 。\n",
      "2 [CLS] 秋 高 气 爽 的 ， 喝 了 一 杯 新 。 喜 欢 各 个 位 ， 聊 着 天 ！ 今 。\n"
     ]
    }
   ],
   "source": [
    "def generate(text, row, col):\n",
    "\n",
    "    def generate_loop(data):\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        #取最后一个字\n",
    "        #[5, b, 50257]\n",
    "        out = out['logits']\n",
    "        #[5, 50257]\n",
    "        out = out[:, -1]\n",
    "\n",
    "        #第50大的值,以此为分界线,小于该值的全部赋值为负无穷\n",
    "        #[5, 50257] -> [5, 50]\n",
    "        topk_value = torch.topk(out, 50).values\n",
    "        #[5, 50] -> [5] -> [5, 1]\n",
    "        topk_value = topk_value[:, -1].unsqueeze(dim=1)\n",
    "\n",
    "        #赋值\n",
    "        #[5, 50257]\n",
    "        out = out.masked_fill(out < topk_value, -float('inf'))\n",
    "\n",
    "        #不允许写特殊符号\n",
    "        out[:, tokenizer.sep_token_id] = -float('inf')\n",
    "        out[:, tokenizer.unk_token_id] = -float('inf')\n",
    "        out[:, tokenizer.pad_token_id] = -float('inf')\n",
    "        for i in '，。':\n",
    "            out[:, tokenizer.get_vocab()[i]] = -float('inf')\n",
    "\n",
    "        #根据概率采样,无放回,所以不可能重复\n",
    "        #[5, 50257] -> [5, 1]\n",
    "        out = out.softmax(dim=1)\n",
    "        out = out.multinomial(num_samples=1)\n",
    "\n",
    "        #强制添加标点符号\n",
    "        c = data['input_ids'].shape[1] / (col + 1)\n",
    "        if c % 1 == 0:\n",
    "            if c % 2 == 0:\n",
    "                out[:, 0] = tokenizer.get_vocab()['。']\n",
    "            else:\n",
    "                out[:, 0] = tokenizer.get_vocab()['，']\n",
    "\n",
    "        data['input_ids'] = torch.cat([data['input_ids'], out], dim=1)\n",
    "        data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "        data['token_type_ids'] = torch.zeros_like(data['input_ids'])\n",
    "        data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "        if data['input_ids'].shape[1] >= row * col + row + 1:\n",
    "            return data\n",
    "\n",
    "        return generate_loop(data)\n",
    "\n",
    "    #重复3遍\n",
    "    data = tokenizer.batch_encode_plus([text] * 3, return_tensors='pt')\n",
    "    data['input_ids'] = data['input_ids'][:, :-1]\n",
    "    data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "    data['token_type_ids'] = torch.zeros_like(data['input_ids'])\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    data = generate_loop(data)\n",
    "\n",
    "    for i in range(3):\n",
    "        print(i, tokenizer.decode(data['input_ids'][i]))\n",
    "\n",
    "\n",
    "generate('秋高气爽', row=4, col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0e6ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    global model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "\n",
    "            select = labels != 0\n",
    "            labels = labels[select]\n",
    "            out = out[select]\n",
    "            del select\n",
    "\n",
    "            accuracy = (labels == out).sum().item() / labels.numel()\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), lr, accuracy)\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    torch.save(model, 'save.model')\n",
    "\n",
    "\n",
    "#train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c6a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS] 秋 高 气 爽 气 ， 独 坐 清 凉 台 。 青 青 万 里 树 ， 照 我 白 鸟 来 。\n",
      "1 [CLS] 秋 高 气 爽 气 ， 一 苇 泛 沧 浪 。 浩 荡 天 地 秋 ， 泠 泠 江 海 霜 。\n",
      "2 [CLS] 秋 高 气 爽 爽 ， 山 寒 夜 清 冷 。 夜 色 日 以 净 ， 秋 光 澹 且 静 。\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('save.model')\n",
    "\n",
    "generate('秋高气爽', row=4, col=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
